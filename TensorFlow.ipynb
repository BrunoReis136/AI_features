{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFhewue0vGZ9va8woxWLbT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoReis136/tensorflow/blob/main/TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST COM CNN"
      ],
      "metadata": {
        "id": "yt38RpWalhui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def model_mnist():\n",
        "  (x_train, y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "  x_train = x_train[..., tf.newaxis].astype(\"float32\") / 255.0\n",
        "  x_test = x_test[..., tf.newaxis].astype(\"float32\") / 255.0\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D((2,2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "    rotation_range = 10,\n",
        "    zoom_range = 0.1,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1\n",
        "  )\n",
        "\n",
        "  datagen.fit(x_train)\n",
        "\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  model.compile(optimizer=\"adam\",\n",
        "                loss=loss_fn,\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  prediction_single_sample = model(x_train[:1])\n",
        "\n",
        "  probabilities_single_sample = tf.nn.softmax(prediction_single_sample).numpy()\n",
        "  print(f'Previsões previstas para a primeira amostra: {probabilities_single_sample}')\n",
        "\n",
        "  loss_single_sample = loss_fn(y_train[:1],prediction_single_sample).numpy()\n",
        "  print(f'Perda para a primeira amostra: {loss_single_sample}')\n",
        "\n",
        "  class myCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.final_acc = None\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      logs = logs or {}\n",
        "      acc = logs.get('accuracy')\n",
        "\n",
        "      if acc is not None and acc > 0.995 :\n",
        "          print('\\nValores de Precisão ou Perda atingidos.')\n",
        "          self.final_acc = acc\n",
        "          self.model.stop_training = True\n",
        "\n",
        "  callback = myCallback()\n",
        "\n",
        "  print('Iniciando treinamento do modelo...')\n",
        "  model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=20, callbacks=[callback])\n",
        "\n",
        "  print('Avaliando modelo...')\n",
        "  model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "  salva_sn = input('Deseja salvar o modelo treinado?(s/n)').lower().strip()\n",
        "\n",
        "  if salva_sn == 's':\n",
        "    if callback.final_acc is not None:\n",
        "      label = round(callback.final_acc,3)*100\n",
        "    else:\n",
        "      label = 'test'\n",
        "\n",
        "    modelo_savepath = f'model_cnn({label}).keras'\n",
        "\n",
        "    try:\n",
        "      model.save(modelo_savepath)\n",
        "      print('Modelo salvo com csucesso.')\n",
        "    except Exception as e:\n",
        "      print(f'Erro ao salvar modelo: {e}')\n",
        "  else:\n",
        "    print('Modelo não salvo.')\n",
        "\n",
        "model_mnist()"
      ],
      "metadata": {
        "id": "Y-TouNUXlgIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1>TESTE PRÁTICO COM WIDGET INPUTS</h1>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eQmzpcgatOg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from ipywidgets import FileUpload, Text, Button, Output, VBox, HBox\n",
        "from IPython.display import display, Image\n",
        "from io import BytesIO\n",
        "from PIL import Image as PILImage # Para manipular a imagem\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_mnist = tf.keras.models.load_model('model_cnn(test).keras')\n",
        "\n",
        "uploader = FileUpload(\n",
        "    accept='image/*',\n",
        "    multiple=False,\n",
        "    description='Carregar Imagem'\n",
        ")\n",
        "\n",
        "label_input = Text(\n",
        "    placeholder='Digite a label correta (dígito de 0 a 9)',\n",
        "    description='Label Correta:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "test_button = Button(\n",
        "    description='Testar Modelo',\n",
        "    button_style='success',\n",
        "    tooltip='Clique para testar o modelo com a imagem e label fornecidas'\n",
        ")\n",
        "\n",
        "output_area = Output()\n",
        "\n",
        "def preprocess_image(image_bytes):\n",
        "    img = PILImage.open(BytesIO(image_bytes)).convert('L')  # escala de cinza\n",
        "    img = img.resize((28, 28))  # redimensionar\n",
        "    img_array = np.array(img) / 255.0  # normalizar\n",
        "    img_array = np.expand_dims(img_array, axis=-1)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array.astype(np.float32)\n",
        "\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "\n",
        "def on_test_button_clicked(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "\n",
        "        if not uploader.value:\n",
        "            print(\"Por favor, carregue uma imagem primeiro.\")\n",
        "            return\n",
        "\n",
        "        if not label_input.value.isdigit() or int(label_input.value) not in range(10):\n",
        "          print(\"Por favor, insira uma label numérica entre 0 e 9.\")\n",
        "          return\n",
        "\n",
        "        uploaded_filename = list(uploader.value.keys())[0]\n",
        "        image_content = uploader.value[uploaded_filename]['content']\n",
        "\n",
        "        try:\n",
        "\n",
        "            processed_image = preprocess_image(image_content)\n",
        "            model_mnist(processed_image)\n",
        "            display(Image(data=image_content, width=200))\n",
        "\n",
        "            predictions = model_mnist.predict(processed_image)\n",
        "            probabilities = tf.nn.softmax(predictions[0]).numpy()\n",
        "            predicted_class_index = np.argmax(probabilities)\n",
        "            predicted_probability = np.max(probabilities)\n",
        "            predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "            true_label = label_input.value.strip().lower()\n",
        "            predicted_label = predicted_class_name.lower()\n",
        "\n",
        "            print(f\"Previsão do Modelo: {predicted_class_name} (Probabilidade: {predicted_probability:.2f})\")\n",
        "            print(f\"Label Correta Informada: {true_label}\")\n",
        "\n",
        "            if predicted_label == true_label:\n",
        "              print(\"Resultado: ✅ O modelo reconheceu corretamente!\")\n",
        "            else:\n",
        "              print(f\"Resultado: ❌ O modelo NÃO reconheceu corretamente. Ele previu '{predicted_class_name}' mas a label correta era '{true_label}'.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ocorreu um erro: {e}\")\n",
        "            print(\"Verifique se o pré-processamento da imagem está correto para o seu modelo (tamanho, canais, normalização).\")\n",
        "\n",
        "\n",
        "test_button.on_click(on_test_button_clicked)\n",
        "\n",
        "input_widgets = VBox([uploader, label_input, test_button])\n",
        "display(VBox([input_widgets, output_area]))"
      ],
      "metadata": {
        "id": "ma0vjJYx3-Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"foto.jpg\")\n",
        "\n",
        "plt.grid = False\n",
        "plt.gray()\n",
        "plt.axis('off')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "image_transformed = np.copy(image.convert('L'))\n",
        "\n",
        "size_x = image_transformed.shape[0]\n",
        "size_y = image_transformed.shape[1]\n",
        "\n",
        "print(f'Tamanho da imagem: {size_x}px por {size_y}px')\n",
        "\n",
        "image = np.array(image.convert('L')).astype(float)\n",
        "\n",
        "filter = [[1, 0, -1],\n",
        "          [1, 0, -1],\n",
        "          [1, 0, -1]]\n",
        "\n",
        "weight = 1\n",
        "\n",
        "for x in range(1, size_x-1):\n",
        "  for y in range(1, size_y-1):\n",
        "    convolution = 0.0\n",
        "    convolution = convolution + (image[x-1, y-1] * filter[0][0])\n",
        "    convolution = convolution + (image[x-1, y] * filter[0][1])\n",
        "    convolution = convolution + (image[x-1, y+1] * filter[0][2])\n",
        "    convolution = convolution + (image[x, y-1] * filter[1][0])\n",
        "    convolution = convolution + (image[x, y] * filter[1][1])\n",
        "    convolution = convolution + (image[x, y+1] * filter[1][2])\n",
        "    convolution = convolution + (image[x+1, y-1] * filter[2][0])\n",
        "    convolution = convolution + (image[x+1, y] * filter[2][1])\n",
        "    convolution = convolution + (image[x+1, y+1] * filter[2][2])\n",
        "\n",
        "    convolution = convolution + weight\n",
        "\n",
        "    if convolution < 0:\n",
        "      convolution = 1\n",
        "    if convolution > 255:\n",
        "      convolution = 255\n",
        "\n",
        "    image_transformed[x,y] = convolution\n",
        "\n",
        "plt.gray()\n",
        "plt.grid =  False\n",
        "plt.imshow(image_transformed)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "new_x = int(size_x /2)\n",
        "new_y = int(size_y /2)\n",
        "\n",
        "newImage = np.zeros((new_x, new_y))\n",
        "\n",
        "for x in range(0, size_x , 2):\n",
        "  for y in range(0, size_y, 2):\n",
        "    pixels = []\n",
        "    pixels.append(image_transformed[x,y])\n",
        "    pixels.append(image_transformed[x+1,y])\n",
        "    pixels.append(image_transformed[x,y+1])\n",
        "    pixels.append(image_transformed[x+1,y+1])\n",
        "\n",
        "    newImage[int(x/2), int(y/2)] = max(pixels)\n",
        "\n",
        "plt.gray()\n",
        "plt.grid = False\n",
        "plt.imshow(newImage)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHjhk44tvLTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train, x_test = x_train[..., tf.newaxis].astype(\"float32\") / 255,x_test[..., tf.newaxis].astype(\"float32\") / 255\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 10,\n",
        "    zoom_range = 0.1,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape = (28, 28, 1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "class callBack(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.final_acc = None\n",
        "  def on_epoch_end(self, epoch, logs = None):\n",
        "    logs = logs or {}\n",
        "    acc = logs.get('accuracy')\n",
        "\n",
        "    if acc is not None and acc > 0.99:\n",
        "      self.final_acc = acc\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callback = callBack()\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=32),\n",
        "    epochs = 10,\n",
        "    callbacks = [callback]\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose = 2)\n"
      ],
      "metadata": {
        "id": "Wfl5vGR1wpox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('images.zip','r') as zip_ref:\n",
        "  zip_ref.extractall('images')\n",
        "\n",
        "ds_train = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"images/images/training\",\n",
        "    image_size=(28,28),\n",
        "    batch_size=32,\n",
        "    label_mode = 'binary'\n",
        ")\n",
        "\n",
        "ds_valid = tf.keras.utils.image_dataset_from_directory(\n",
        "    'images/images/validation',\n",
        "    image_size = (300,300),\n",
        "    batch_size = 32,\n",
        "    label_mode = 'binary'\n",
        ")\n",
        "\n",
        "rescale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "\n",
        "ds_train_rescaled = ds_train.map(lambda image, label:(rescale_layer(image), label))\n",
        "ds_valid_rescaled = ds_valid.map(lambda image, label:(rescale_layer(image), label))\n",
        "\n",
        "ds_train_final = (ds_train_rescaled.cache().shuffle(buffer_size = 1000).prefetch(buffer_size = tf.data.AUTOTUNE))\n",
        "ds_valid_final = (ds_valid_rescaled.cache().prefetch(buffer_size = tf.data.AUTOTUNE))\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28,28,3)),\n",
        "    tf.keras.layers.Conv2D(16, (3,3),activation='relu')\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(32, (3,3),activation='relu')\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3),activation='relu')\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten()\n",
        "    tf.keras.Dente(512,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2)\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "model.compile(\n",
        "    loss='binary-crossentropy',\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    metric = 'accuracy'\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train_final,\n",
        "    epochs = 15,\n",
        "    validation_data = ds_valid_final,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "SuHpk0FRI2OW",
        "outputId": "79954135-0e1e-4e86-db0c-dcf6ab01bc8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28 files belonging to 2 classes.\n",
            "Found 28 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar xvjf LJSpeech-1.1.tar.bz2'''\n",
        "#download LJSpeech-1.1  dataset de TTS"
      ],
      "metadata": {
        "id": "YU-yuiIToAO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "\n",
        "metadata = pd.read_csv('LJSpeech-1.1/metadata.csv', sep=\"|\", header=None)\n",
        "metadata.columns = ['file_id', 'text', 'normalized_text']\n",
        "\n",
        "file_name = metadata.iloc[2000]['file_id']\n",
        "\n",
        "audio_path = f'LJSpeech-1.1/wavs/{file_name}.wav'\n",
        "\n",
        "display(Audio(filename=audio_path))\n",
        "\n",
        "def load_mel(file_path):\n",
        "  y, sr = librosa.load(file_path, sr=22050)\n",
        "  mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=256, n_mels=80)\n",
        "  mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "  return mel_db\n",
        "\n",
        "mel_db = load_mel(audio_path)\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "librosa.display.specshow(mel_db.T, sr=22050, hop_length=256, x_axis='time', y_axis='mel')\n",
        "\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel Spectrogram (dB)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "glE0cIuooA_x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}