{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwtm6uCc+DtONMuDiTfV2g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoReis136/tensorflow/blob/main/TensorFlowTTSadvanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TTS -  DOWNLOAD DO DATASET LJSPEECH </h1>"
      ],
      "metadata": {
        "id": "8mbBho6YF0lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar xvjf LJSpeech-1.1.tar.bz2\n",
        "#download LJSpeech-1.1  dataset de TTS"
      ],
      "metadata": {
        "id": "YU-yuiIToAO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>CONVERTER ARQUIVOS DE ÁUDIO PARA PADRÕES RATE/CHANNEL/WIDTH</h2>"
      ],
      "metadata": {
        "id": "TSD88gWh1GX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "nNsFO69sysw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6302f9b4-d896-4393-d60f-7e5ca20c3e52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_dir = \"LJSpeech-1.1/wavs\"\n",
        "output_dir = \"LJSpeech-1.1/wavs16k\"\n",
        "\n",
        "for filename in tqdm(os.listdir(input_dir)):\n",
        "  if filename.endswith(\".wav\"):\n",
        "    filepath = os.path.join(input_dir, filename)\n",
        "    audio = AudioSegment.from_wav(filepath)\n",
        "\n",
        "    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)\n",
        "\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    audio.export(output_path, format=\"wav\")"
      ],
      "metadata": {
        "id": "tcsaUGLZy0I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Testando o formato dos áudios convertidos</h2>"
      ],
      "metadata": {
        "id": "Q3ou2rYe2tu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "\n",
        "with wave.open(\"LJSpeech-1.1/wavs16k/LJ001-0001.wav\", \"rb\") as wav_file:\n",
        "    print(\"Frequência:\", wav_file.getframerate())\n",
        "    print(\"Canais:\", wav_file.getnchannels())\n",
        "    print(\"Sample width:\", wav_file.getsampwidth())  # Deve ser 2 (16-bit)"
      ],
      "metadata": {
        "id": "jwdTISJy1xxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Dataframe dos metadatas e coluna com caminho dos arquivos</h2>"
      ],
      "metadata": {
        "id": "kjZddvjq23vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "metadata = pd.read_csv('LJSpeech-1.1/metadata.csv',sep=\"|\", header=None)\n",
        "metadata.columns = ['file_id', 'text', 'normalized_text']\n",
        "metadata['wav_path'] = metadata['file_id'].apply(lambda x:f'LJSpeech-1.1/wav16k/{x}.wav')"
      ],
      "metadata": {
        "id": "DxMIWk9s2rZl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extrair Mel com Librosa: FUNÇÃO</h2>"
      ],
      "metadata": {
        "id": "3TEfR-BP4AJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_wav_to_mel(input_dir,\n",
        "                       output_dir,\n",
        "                       sr=16000,\n",
        "                       n_fft=1024,\n",
        "                       hop_length=256,\n",
        "                       n_mels=80,\n",
        "                       power=1.0,\n",
        "                       to_db=True,\n",
        "                       verbose=True):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    file_list = [f for f in os.listdir(input_dir) if f.endswith(\".wav\")]\n",
        "    iterator = tqdm(file_list, desc=\"Convertendo WAV → Mel\") if verbose else file_list\n",
        "\n",
        "    for filename in iterator:\n",
        "        filepath = os.path.join(input_dir, filename)\n",
        "        output_path = os.path.join(output_dir, filename.replace(\".wav\", \".npy\"))\n",
        "\n",
        "        y, _ = librosa.load(filepath, sr=sr)\n",
        "\n",
        "        mel = librosa.feature.melspectrogram(\n",
        "            y=y,\n",
        "            sr=sr,\n",
        "            n_fft=n_fft,\n",
        "            hop_length=hop_length,\n",
        "            n_mels=n_mels,\n",
        "            power=power\n",
        "        )\n",
        "\n",
        "        if to_db:\n",
        "            mel = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "        np.save(output_path, mel)"
      ],
      "metadata": {
        "id": "6SkFHRn84V1-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extrair Mel com Librosa: EXECUÇÃO</h2>"
      ],
      "metadata": {
        "id": "Cahpmtk2sItT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convert_wav_to_mel(\n",
        "    input_dir=\"LJSpeech-1.1/wavs16k\",\n",
        "    output_dir=\"LJSpeech-1.1/mels\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDpNUShYsGXs",
        "outputId": "09e18bae-882a-4739-df97-756003e1ebba"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Convertendo WAV → Mel: 100%|██████████| 13100/13100 [03:26<00:00, 63.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Visualização do spectrograma (somente por diversão)</h2>"
      ],
      "metadata": {
        "id": "GcYoRifi5IKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "mel = np.load(\"LJSpeech-1.1/mels/LJ001-0001.npy\")\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mel, sr=16000, hop_length=256, x_axis=\"time\", y_axis=\"mel\")\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.title(\"Mel Spectrogram\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A1r2jeXnrJ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Dados tabulares para Dataframe e Pré Processamento</h2>"
      ],
      "metadata": {
        "id": "LflNfqS55c-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('LJSpeech-1.1/metadata.csv',\n",
        "                       sep=\"|\",\n",
        "                       header=None,\n",
        "                       names=['file_id', 'text', 'normalized_text'])\n",
        "\n",
        "df['normalized_text'].fillna(df['text'],inplace=True)\n",
        "df['normalized_text'].dropna(inplace=True)"
      ],
      "metadata": {
        "id": "cZHqu8vP5chG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Tokenizar textos por BPE(byte pair encoding): Função</h2>"
      ],
      "metadata": {
        "id": "fVKgSkCS65-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "\n",
        "def train_sentencepiece(\n",
        "    texts,                 # lista de strings ou pd.Series com frases normalizadas\n",
        "    input_txt_path='temp_text.txt',  # arquivo temporário para salvar as frases\n",
        "    model_prefix='spm_model',        # prefixo do modelo e vocab\n",
        "    vocab_size=200                   # tamanho do vocabulário\n",
        "):\n",
        "    # Salva os textos em um arquivo temporário\n",
        "    with open(input_txt_path, 'w', encoding='utf-8') as f:\n",
        "        for line in texts:\n",
        "            f.write(line.strip() + '\\n')\n",
        "\n",
        "    # Treina o modelo SentencePiece\n",
        "    spm.SentencePieceTrainer.Train(\n",
        "        input=input_txt_path,\n",
        "        model_prefix=model_prefix,\n",
        "        vocab_size=vocab_size\n",
        "    )\n",
        "\n",
        "    # (Opcional) Remove o arquivo temporário após treino\n",
        "    if os.path.exists(input_txt_path):\n",
        "        os.remove(input_txt_path)\n",
        "\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    sp.load(f'{model_prefix}.model' )\n",
        "\n",
        "    # Adiciona ao DataFrame\n",
        "    df[\"tokens_bpe\"] = texts.apply(lambda t: sp.encode(t, out_type=int))"
      ],
      "metadata": {
        "id": "xYImb0oI7Aou"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Tokenizar textos por BPE(byte pair encoding): Aplicação</h2>"
      ],
      "metadata": {
        "id": "VWt3mbvxtE-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentencepiece(\n",
        "    texts=df['normalized_text'],\n",
        "    input_txt_path='temp_text.txt',\n",
        "    model_prefix='spm_model',\n",
        "    vocab_size=700\n",
        ")"
      ],
      "metadata": {
        "id": "t0yyLwlgtELx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_pickle('LJSpeech_preprocessed.pkl')"
      ],
      "metadata": {
        "id": "YAep2_wLwAjn"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}