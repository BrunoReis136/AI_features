{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFmxxISvnZSjiwj8du+OWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoReis136/tensorflow/blob/main/TensorFlowTTSadvanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TTS -  DOWNLOAD DO DATASET LJSPEECH </h1>"
      ],
      "metadata": {
        "id": "8mbBho6YF0lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar xvjf LJSpeech-1.1.tar.bz2\n",
        "#download LJSpeech-1.1  dataset de TTS"
      ],
      "metadata": {
        "id": "YU-yuiIToAO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>CONVERTER ARQUIVOS DE ÁUDIO PARA PADRÕES RATE/CHANNEL/WIDTH</h2>"
      ],
      "metadata": {
        "id": "TSD88gWh1GX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "nNsFO69sysw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_dir = \"LJSpeech-1.1/wavs\"\n",
        "output_dir = \"LJSpeech-1.1/wavs16k\"\n",
        "\n",
        "for filename in tqdm(os.listdir(input_dir)):\n",
        "  if filename.endswith(\".wav\"):\n",
        "    filepath = os.path.join(input_dir, filename)\n",
        "    audio = AudioSegment.from_wav(filepath)\n",
        "\n",
        "    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)\n",
        "\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    audio.export(output_path, format=\"wav\")"
      ],
      "metadata": {
        "id": "tcsaUGLZy0I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extrair Mel com Librosa: FUNÇÃO</h2>"
      ],
      "metadata": {
        "id": "3TEfR-BP4AJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_wav_to_mel(input_dir,\n",
        "                       output_dir,\n",
        "                       sr=16000,\n",
        "                       n_fft=1024,\n",
        "                       hop_length=256,\n",
        "                       n_mels=80,\n",
        "                       power=1.0,\n",
        "                       to_db=True,\n",
        "                       verbose=True):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    file_list = [f for f in os.listdir(input_dir) if f.endswith(\".wav\")]\n",
        "    iterator = tqdm(file_list, desc=\"Convertendo WAV → Mel\") if verbose else file_list\n",
        "\n",
        "    for filename in iterator:\n",
        "        filepath = os.path.join(input_dir, filename)\n",
        "        output_path = os.path.join(output_dir, filename.replace(\".wav\", \".npy\"))\n",
        "\n",
        "        # Carrega o áudio com taxa de amostragem desejada (sr)\n",
        "        y, _ = librosa.load(filepath, sr=sr)\n",
        "\n",
        "        # Calcula mel spectrograma (potência ou magnitude ao quadrado)\n",
        "        mel = librosa.feature.melspectrogram(\n",
        "            y=y,\n",
        "            sr=sr,\n",
        "            n_fft=n_fft,\n",
        "            hop_length=hop_length,\n",
        "            n_mels=n_mels,\n",
        "            power=power  # geralmente 1.0 para magnitude, 2.0 para potência\n",
        "        )\n",
        "\n",
        "        # Converte para escala dB para facilitar o treino e normalização\n",
        "        if to_db:\n",
        "            mel = librosa.power_to_db(mel, ref=np.max)  # normaliza pelo valor máximo do mel do áudio\n",
        "\n",
        "        # Salva o mel spectrograma em formato numpy para acesso rápido no treino\n",
        "        np.save(output_path, mel)\n"
      ],
      "metadata": {
        "id": "6SkFHRn84V1-"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extrair Mel com Librosa: EXECUÇÃO</h2>"
      ],
      "metadata": {
        "id": "Cahpmtk2sItT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convert_wav_to_mel(\n",
        "    input_dir=\"LJSpeech-1.1/wavs16k\",\n",
        "    output_dir=\"LJSpeech-1.1/mels\"\n",
        ")"
      ],
      "metadata": {
        "id": "qDpNUShYsGXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a74fe1d-9e73-4b9b-f945-19781aa29743"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Convertendo WAV → Mel: 100%|██████████| 13100/13100 [04:26<00:00, 49.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Visualização do spectrograma (somente por diversão)</h2>"
      ],
      "metadata": {
        "id": "GcYoRifi5IKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "mel = np.load(\"LJSpeech-1.1/mels/LJ001-0001.npy\")\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mel, sr=16000, hop_length=256, x_axis=\"time\", y_axis=\"mel\")\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.title(\"Mel Spectrogram\")\n",
        "plt.tight_layout()\n",
        "plt.show()'''"
      ],
      "metadata": {
        "id": "A1r2jeXnrJ1M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e82000a4-3d4e-46f9-e665-0f0cec147cef"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import matplotlib.pyplot as plt\\nimport librosa.display\\n\\nmel = np.load(\"LJSpeech-1.1/mels/LJ001-0001.npy\")\\nplt.figure(figsize=(10, 4))\\nlibrosa.display.specshow(mel, sr=16000, hop_length=256, x_axis=\"time\", y_axis=\"mel\")\\nplt.colorbar(format=\"%+2.0f dB\")\\nplt.title(\"Mel Spectrogram\")\\nplt.tight_layout()\\nplt.show()'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Com os dados prontos, pode reiniciar daqui:===========================================***"
      ],
      "metadata": {
        "id": "bHLUJ-yX-KjH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Dados tabulares para Dataframe e Pré Processamento</h2>"
      ],
      "metadata": {
        "id": "LflNfqS55c-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "df = pd.read_csv('LJSpeech-1.1/metadata.csv',\n",
        "                       sep=\"|\",\n",
        "                       header=None,\n",
        "                       names=['file_id', 'text', 'normalized_text'])\n",
        "\n",
        "df['normalized_text'].fillna(df['text'],inplace=True)\n",
        "\n",
        "df['normalized_text'].dropna(inplace=True)\n",
        "\n",
        "df['wav_path'] = df['file_id'].apply(lambda x:f'LJSpeech-1.1/wav16k/{x}.wav')\n",
        "\n",
        "df[\"mel_path\"] = df[\"file_id\"].apply(lambda x: f\"LJSpeech-1.1/mels/{x}.npy\")"
      ],
      "metadata": {
        "id": "cZHqu8vP5chG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f1d11e5-b58d-4a62-f7f0-997ea67b85c0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-84-4110074409.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['normalized_text'].fillna(df['text'],inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Tokenizar textos por BPE(byte pair encoding): Função</h2>"
      ],
      "metadata": {
        "id": "fVKgSkCS65-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "import os\n",
        "\n",
        "def train_sentencepiece(\n",
        "    texts,                 # lista de strings ou pd.Series com frases normalizadas\n",
        "    input_txt_path='temp_text.txt',  # arquivo temporário para salvar as frases\n",
        "    model_prefix='spm_model',        # prefixo do modelo e vocab\n",
        "    vocab_size=200                   # tamanho do vocabulário\n",
        "):\n",
        "    # Salva os textos em um arquivo temporário\n",
        "    with open(input_txt_path, 'w', encoding='utf-8') as f:\n",
        "        for line in texts:\n",
        "            f.write(line.strip() + '\\n')\n",
        "\n",
        "    # Treina o modelo SentencePiece\n",
        "    spm.SentencePieceTrainer.Train(\n",
        "        input=input_txt_path,\n",
        "        model_prefix=model_prefix,\n",
        "        vocab_size=vocab_size\n",
        "    )\n",
        "\n",
        "    # (Opcional) Remove o arquivo temporário após treino\n",
        "    if os.path.exists(input_txt_path):\n",
        "        os.remove(input_txt_path)\n",
        "\n",
        "    sp = spm.SentencePieceProcessor()\n",
        "    sp.load(f'{model_prefix}.model' )\n",
        "\n",
        "    # Adiciona ao DataFrame\n",
        "    df[\"tokens_bpe\"] = texts.apply(lambda t: sp.encode(t, out_type=int))"
      ],
      "metadata": {
        "id": "xYImb0oI7Aou"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Tokenizar textos por BPE(byte pair encoding): Aplicação</h2>"
      ],
      "metadata": {
        "id": "VWt3mbvxtE-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentencepiece(\n",
        "    texts=df['normalized_text'],\n",
        "    input_txt_path='temp_text.txt',\n",
        "    model_prefix='spm_model',\n",
        "    vocab_size=700\n",
        ")"
      ],
      "metadata": {
        "id": "t0yyLwlgtELx"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Salva o dataframe como arquivo picke(.pkl)</h2>"
      ],
      "metadata": {
        "id": "ks4UYq_KDk4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_pickle('LJSpeech_preprocessed.pkl')"
      ],
      "metadata": {
        "id": "YAep2_wLwAjn"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Cria Classe Dataset para converter tokens/mels em tensores e retornar</h2>"
      ],
      "metadata": {
        "id": "pDixsVBnDxw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TTSDataset(Dataset):\n",
        "    def __init__(self, dataframe, mel_dir=None, pad_token=0, max_input_length=None, max_mel_length=None):\n",
        "        self.df = dataframe.sample(n=100).reset_index(drop=True)  # AQUI DEFINIMOS A QUANTIDADE DE AMOSTRAS DE ACORDO COM O PODER DE PROCESSAMENTO DO AMBIENTE\n",
        "        self.mel_dir = mel_dir\n",
        "        self.pad_token = pad_token\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_mel_length = max_mel_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.df.iloc[idx]\n",
        "        tokens = row['tokens_bpe']\n",
        "        filename = row['file_id'] + \".npy\"\n",
        "\n",
        "        mel_path = os.path.join(self.mel_dir, filename) if self.mel_dir else row['mel_path']\n",
        "        mel = np.load(mel_path)\n",
        "\n",
        "        tokens = torch.LongTensor(tokens)\n",
        "        mel = torch.tensor(mel, dtype=torch.float32)\n",
        "\n",
        "        return tokens, mel"
      ],
      "metadata": {
        "id": "2MDnyIlY9vCd"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Função de padding dinâmico ao carregar os dados no DataLoader</h2>"
      ],
      "metadata": {
        "id": "2cQDdgO1EC-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tts_collate_fn(batch):\n",
        "    input_seqs, mel_specs = zip(*batch)\n",
        "\n",
        "    # Pad dos tokens\n",
        "    input_lengths = [len(seq) for seq in input_seqs]\n",
        "    max_input_length = max(input_lengths)\n",
        "    input_padded = torch.zeros(len(batch), max_input_length, dtype=torch.long)\n",
        "\n",
        "    for i, seq in enumerate(input_seqs):\n",
        "        input_padded[i, :len(seq)] = seq  # ✅ CORRETA\n",
        "\n",
        "    # Pad dos mel specs (formato = [n_mel, T])\n",
        "    mel_lengths = [mel.shape[1] for mel in mel_specs]\n",
        "    max_mel_len = max(mel_lengths)\n",
        "    n_mels = mel_specs[0].shape[0]\n",
        "    mel_padded = torch.zeros(len(batch), n_mels, max_mel_len)\n",
        "\n",
        "    for i, mel in enumerate(mel_specs):\n",
        "        mel_padded[i, :, :mel.shape[1]] = mel\n",
        "\n",
        "    mel_padded = mel_padded.transpose(1, 2)\n",
        "\n",
        "\n",
        "    return input_padded, torch.tensor(input_lengths), mel_padded, torch.tensor(mel_lengths)"
      ],
      "metadata": {
        "id": "1Ehau_TPDkMr"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Carregando dados com DataLoader</h2>\n"
      ],
      "metadata": {
        "id": "B7WFataVIQEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "\n",
        "# Carregando Dataframe com token_bpe e mel_path\n",
        "# se necessário puxar o dataframe em df = pd.read_picke('LJSpeech_preprocessed')\n",
        "df = pd.read_pickle('LJSpeech_preprocessed.pkl')\n",
        "\n",
        "dataset = TTSDataset(df)\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=tts_collate_fn)\n",
        "\n",
        "for batch in loader:\n",
        "    input_ids, input_lengths, mel_specs, mel_lengths = batch\n",
        "    break"
      ],
      "metadata": {
        "id": "BzaQzh1uIWVn"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Começando o modelo TACOTRON 2"
      ],
      "metadata": {
        "id": "Ko1RiQqq4HMI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Dependências</h2>"
      ],
      "metadata": {
        "id": "vgq9-IhB7s4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "Fyw2deot7tWb"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Classe Embedding + Encoder</h2>"
      ],
      "metadata": {
        "id": "hO2t6BYC4NbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim=256, encoder_dim=512):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv1d(embedding_dim, encoder_dim, kernel_size=5, padding=2),\n",
        "            nn.BatchNorm1d(encoder_dim),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.lstm = nn.LSTM(encoder_dim, encoder_dim // 2, batch_first=True, bidirectional=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: [B, T]\n",
        "        x = self.embedding(x)  # [B, T, E]\n",
        "        x = x.transpose(1, 2)  # [B, E, T]\n",
        "        x = self.conv1(x)      # [B, C, T]\n",
        "        x = x.transpose(1, 2)  # [B, T, C]\n",
        "        output, _ = self.lstm(x)\n",
        "        return output  # [B, T, C]\n"
      ],
      "metadata": {
        "id": "KpmRc2me4MU2"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Classe Attention</h2>"
      ],
      "metadata": {
        "id": "LChQDvku6PF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, encoder_dim, decoder_dim):\n",
        "        super().__init__()\n",
        "        self.query_proj = nn.Linear(decoder_dim, decoder_dim)\n",
        "        self.key_proj = nn.Linear(encoder_dim, decoder_dim)\n",
        "        self.energy_proj = nn.Linear(decoder_dim, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        # query: [B, decoder_dim]\n",
        "        # keys:  [B, T_enc, encoder_dim]\n",
        "        q = self.query_proj(query).unsqueeze(1)  # [B, 1, D]\n",
        "        k = self.key_proj(keys)                  # [B, T_enc, D]\n",
        "        energy = self.energy_proj(torch.tanh(q + k))  # [B, T_enc, 1]\n",
        "        weights = F.softmax(energy.squeeze(-1), dim=-1)  # [B, T_enc]\n",
        "        context = torch.bmm(weights.unsqueeze(1), keys).squeeze(1)  # [B, encoder_dim]\n",
        "        return context, weights\n"
      ],
      "metadata": {
        "id": "q5t1dn616R7d"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Classe Decoder</h2>"
      ],
      "metadata": {
        "id": "Q9ACV3ur7mqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, encoder_dim, mel_dim=80, decoder_dim=1024):\n",
        "        super().__init__()\n",
        "        self.mel_dim = mel_dim\n",
        "        self.decoder_dim = decoder_dim\n",
        "        self.max_decoder_steps = 1000  # Limite de inferência\n",
        "\n",
        "        self.prenet = nn.Sequential(\n",
        "            nn.Linear(mel_dim, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5)\n",
        "        )\n",
        "\n",
        "        self.attention = Attention(encoder_dim, decoder_dim)\n",
        "        self.lstm1 = nn.LSTMCell(256 + encoder_dim, decoder_dim)\n",
        "        self.linear = nn.Linear(decoder_dim, mel_dim)\n",
        "\n",
        "    def forward(self, encoder_out, mel_inputs, teacher_forcing=True):\n",
        "        B, T, _ = mel_inputs.shape\n",
        "        mel_outputs = []\n",
        "        attention_weights = []\n",
        "\n",
        "        h, c = [torch.zeros(B, self.decoder_dim).to(encoder_out.device)] * 2\n",
        "        prev_mel = mel_inputs[:, 0, :]  # [B, mel_dim]\n",
        "\n",
        "        for t in range(1, T):\n",
        "            prenet_out = self.prenet(prev_mel)\n",
        "            context, attn = self.attention(h, encoder_out)\n",
        "            rnn_input = torch.cat([prenet_out, context], dim=-1)\n",
        "            h, c = self.lstm1(rnn_input, (h, c))\n",
        "            mel_out = self.linear(h)\n",
        "\n",
        "            mel_outputs.append(mel_out.unsqueeze(1))       # [B, 1, mel_dim]\n",
        "            attention_weights.append(attn.unsqueeze(1))    # [B, 1, T_enc]\n",
        "\n",
        "            prev_mel = mel_inputs[:, t, :] if teacher_forcing else mel_out\n",
        "\n",
        "        mel_outputs = torch.cat(mel_outputs, dim=1)\n",
        "        attention_weights = torch.cat(attention_weights, dim=1)\n",
        "        return mel_outputs, attention_weights\n",
        "\n",
        "    def inference(self, memory):\n",
        "        batch_size = memory.size(0)\n",
        "        device = memory.device\n",
        "        T_enc = memory.size(1)\n",
        "\n",
        "        h, c = [torch.zeros(batch_size, self.decoder_dim).to(device)] * 2\n",
        "        prev_mel = torch.zeros(batch_size, self.mel_dim).to(device)\n",
        "\n",
        "        mel_outputs = []\n",
        "        attention_weights = []\n",
        "\n",
        "        for _ in range(self.max_decoder_steps):\n",
        "            prenet_out = self.prenet(prev_mel)\n",
        "            context, attn = self.attention(h, memory)\n",
        "            rnn_input = torch.cat([prenet_out, context], dim=-1)\n",
        "            h, c = self.lstm1(rnn_input, (h, c))\n",
        "            mel_out = self.linear(h)\n",
        "\n",
        "            mel_outputs.append(mel_out.unsqueeze(1))\n",
        "            attention_weights.append(attn.unsqueeze(1))\n",
        "\n",
        "            prev_mel = mel_out\n",
        "\n",
        "        mel_outputs = torch.cat(mel_outputs, dim=1)\n",
        "        attention_weights = torch.cat(attention_weights, dim=1)\n",
        "        return mel_outputs, mel_outputs, attention_weights\n"
      ],
      "metadata": {
        "id": "mNzLVP__7oC_"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Postnet (Refinamento final)</h2>"
      ],
      "metadata": {
        "id": "RPvox_c39gZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Postnet(nn.Module):\n",
        "    def __init__(self, mel_dim=80):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv1d(mel_dim, 512, kernel_size=5, padding=2),\n",
        "            nn.Tanh(),\n",
        "            nn.Conv1d(512, mel_dim, kernel_size=5, padding=2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.transpose(1, 2)  # [B, 80, T]\n",
        "        x = self.conv(x)\n",
        "        x = x.transpose(1, 2)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "rOxf1rUF9iU4"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Modelo Tacotron 2</h2>"
      ],
      "metadata": {
        "id": "8UgWHNus9kA-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tacotron2(nn.Module):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(vocab_size)\n",
        "        self.decoder = Decoder(encoder_dim=512)\n",
        "        self.postnet = Postnet()\n",
        "\n",
        "    def forward(self, input_ids, mel_inputs, teacher_forcing=True):\n",
        "        enc_out = self.encoder(input_ids)  # [B, T, 512]\n",
        "        mel_outputs, attn = self.decoder(enc_out, mel_inputs, teacher_forcing)\n",
        "        mel_refined = mel_outputs + self.postnet(mel_outputs)\n",
        "        return mel_outputs, mel_refined, attn\n",
        "\n",
        "    def infer(self, input_ids):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            memory = self.encoder(input_ids)\n",
        "            mel_outputs, mel_postnet_outputs, _ = self.decoder.inference(memory)\n",
        "            mel_refined = mel_postnet_outputs + self.postnet(mel_postnet_outputs)\n",
        "        return mel_outputs, mel_refined"
      ],
      "metadata": {
        "id": "1hfhrawH9ppx"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Função de perda</h2>"
      ],
      "metadata": {
        "id": "ncq2nA_g-Fad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tacotron_loss(mel_outputs, mel_refined, mel_targets):\n",
        "    loss1 = F.l1_loss(mel_outputs, mel_targets)\n",
        "    loss2 = F.l1_loss(mel_refined, mel_targets)\n",
        "    return loss1 + loss2"
      ],
      "metadata": {
        "id": "8cjK0AHc-JWq"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Função de Treino </h2>"
      ],
      "metadata": {
        "id": "80IIv-zk-LRk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, dataloader, optimizer, device, num_epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0.0\n",
        "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
        "            input_ids, input_lengths, mel_specs, mel_lengths = batch\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            mel_specs = mel_specs.to(device)\n",
        "\n",
        "            # Forward\n",
        "            mel_out, mel_postnet, _ = model(input_ids, mel_specs)\n",
        "\n",
        "            # ✅ Ajuste de tamanhos\n",
        "            min_len = min(mel_out.shape[1], mel_specs.shape[1], mel_postnet.shape[1])\n",
        "            mel_out = mel_out[:, :min_len, :]\n",
        "            mel_postnet = mel_postnet[:, :min_len, :]\n",
        "            mel_specs = mel_specs[:, :min_len, :]\n",
        "\n",
        "            # Loss\n",
        "            loss = tacotron_loss(mel_out, mel_postnet, mel_specs)\n",
        "\n",
        "            # Backprop\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_loss = total_loss / len(dataloader)\n",
        "        print(f\"Epoch {epoch+1} - Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "fg5f40Fr-K45"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Treinamento do modelo Iteradamente com repetições </h2>"
      ],
      "metadata": {
        "id": "Wf7BbgJe-Wgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "full_dataframe = pd.read_pickle(\"LJSpeech_preprocessed.pkl\")\n",
        "num_samples = len(df)    # ex: 13500\n",
        "batch_size = 100\n",
        "num_batches = (num_samples + batch_size - 1) // batch_size  # ceil\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "\n",
        "    # Shuffle o dataframe no início de cada época\n",
        "    full_dataframe = full_dataframe.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "    for batch_idx in range(num_batches):\n",
        "        start = batch_idx * batch_size\n",
        "        end = min((batch_idx + 1) * batch_size, num_samples)\n",
        "\n",
        "        sub_df = full_dataframe.iloc[start:end]\n",
        "\n",
        "        # Cria dataset e dataloader com só este pedaço\n",
        "        subset_dataset = TTSDataset(sub_df, mel_dir='LJSpeech-1.1/mels')\n",
        "        subset_loader = DataLoader(subset_dataset, batch_size=8, shuffle=True, collate_fn=tts_collate_fn)\n",
        "\n",
        "        # Treina no subset por uma época (ou número fixo de iterações)\n",
        "        train(model, subset_loader, optimizer, device, num_epochs=1)\n"
      ],
      "metadata": {
        "id": "lECyUF4n-ba0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb3bcaee-bf8d-4b0c-d87a-858bd0628182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:   0%|          | 0/13 [00:00<?, ?it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Salvar Modelo </h2>"
      ],
      "metadata": {
        "id": "pUQbNgneERsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"model\", exist_ok=True)\n",
        "\n",
        "torch.save(model.state_dict(), \"model/tacotron2_weights.pth\")"
      ],
      "metadata": {
        "id": "tRxHuP7DERGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Carregando o modelo </h2>"
      ],
      "metadata": {
        "id": "Sezn1vE5E3Mp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assumindo que você treinou com SentencePiece ou similar\n",
        "vocab_size = len(sp)  # seu SentencePieceProcessor deve estar carregado\n",
        "\n",
        "# Criar e carregar modelo\n",
        "model = Tacotron2(vocab_size=vocab_size)\n",
        "model.load_state_dict(torch.load(\"model/tacotron2_weights.pth\", map_location=device))\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(\"✅ Modelo carregado e pronto para inferência.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "IlN4cU9pE3qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Configuração para uso do modelo </h2>"
      ],
      "metadata": {
        "id": "jwzWnxPcF9wU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''Carregar no diretório local os arquivos necessários\n",
        "\n",
        "├── tacotron2_weights.pth       # pesos do modelo treinado\n",
        "├── config.json                 # parâmetros (vocab_size, n_mels, etc)\n",
        "├── spm_model.model             # modelo SentencePiece\n",
        "├── classes necessárias:\n",
        "        Tacotron2\n",
        "        Classe principal que encapsula encoder, decoder e postnet.\n",
        "\n",
        "        Encoder\n",
        "        Codifica os tokens de entrada (IDs) em vetores de características.\n",
        "\n",
        "        Decoder\n",
        "        Gera os frames de mel spectrograma a partir do encoder.\n",
        "\n",
        "        Postnet\n",
        "        Rede convolucional para refinar os espectrogramas.\n",
        "\n",
        "        Attention\n",
        "        Mecanismo de atenção dentro do decoder.\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "import json\n",
        "\n",
        "# Carregar config\n",
        "with open(\"config.json\", \"r\") as f:\n",
        "    config = json.load(f)\n",
        "\n",
        "# Usar os parâmetros\n",
        "vocab_size = config[\"vocab_size\"]\n",
        "n_mels = config[\"n_mels\"]\n",
        "n_fft = config[\"n_fft\"]\n",
        "hop_length = config[\"hop_length\"]\n",
        "sr = config[\"sampling_rate\"]\n",
        "\n",
        "# Carregar SentencePiece\n",
        "import sentencepiece as spm\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load(config[\"spm_model\"])\n",
        "'''"
      ],
      "metadata": {
        "id": "uz_bI0fTF-Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Função pra utilizar o modelo </h1>"
      ],
      "metadata": {
        "id": "IJg8zid4FFY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import soundfile as sf  # para salvar WAV\n",
        "import torch\n",
        "\n",
        "def tts_infer(text, model, sp, device, sr=16000, n_fft=1024, hop_length=256, n_mels=80):\n",
        "    model.eval()\n",
        "\n",
        "    # Tokenizar entrada\n",
        "    tokens = sp.encode(text, out_type=int)\n",
        "    tokens = torch.LongTensor(tokens).unsqueeze(0).to(device)  # [1, T]\n",
        "\n",
        "    # Rodar modelo usando o método infer()\n",
        "    with torch.no_grad():\n",
        "        mel_out, mel_postnet = model.infer(tokens)  # [1, T, n_mels] ou [1, n_mels, T]\n",
        "\n",
        "    mel = mel_postnet.squeeze(0).cpu().numpy()\n",
        "\n",
        "    # Ajusta shape para (n_mels, T)\n",
        "    if mel.shape[0] != n_mels:\n",
        "        mel = mel.T\n",
        "\n",
        "    print(f\"Shape do mel: {mel.shape}, min: {mel.min()}, max: {mel.max()}\")\n",
        "\n",
        "    # Se seu mel foi convertido para escala dB, converta de volta para potência\n",
        "    mel = librosa.db_to_power(mel)\n",
        "\n",
        "    # Se normalizou os mels, reverta aqui\n",
        "    # mel = mel * std + mean  # descomente e defina mean/std se usar\n",
        "\n",
        "    # Reconstruir áudio com Griffin-Lim\n",
        "    wav = librosa.feature.inverse.mel_to_audio(\n",
        "        mel,\n",
        "        sr=sr,\n",
        "        n_fft=n_fft,\n",
        "        hop_length=hop_length,\n",
        "        power=1.0  # corresponde a magnitude, e mel deve ser magnitude ao quadrado se power=2\n",
        "    )\n",
        "\n",
        "    output_path = \"output.wav\"\n",
        "    sf.write(output_path, wav, sr)\n",
        "    print(f\"✅ Áudio gerado e salvo como: {output_path}\")\n"
      ],
      "metadata": {
        "id": "pO6VyslSFFAX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2> Input de texto e saída de áudio </h2>"
      ],
      "metadata": {
        "id": "aRyNLQAKFRT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "texto = input(f\"Escreva um texto pra gerar um áudio: \\n\")\n",
        "\n",
        "tts_infer(texto, model, sp, device)\n",
        "\n",
        "audio_path = \"output.wav\"\n",
        "\n",
        "Audio(audio_path)"
      ],
      "metadata": {
        "id": "yMFKCO1eFcnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HAo1uAmYf-l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}