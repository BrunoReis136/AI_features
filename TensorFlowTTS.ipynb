{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqHnUW3HHnCe+w7bbT95AH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoReis136/tensorflow/blob/main/TensorFlowTTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TTS -  DOWNLOAD DO DATASET LJSPEECH </h1>"
      ],
      "metadata": {
        "id": "8mbBho6YF0lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar xvjf LJSpeech-1.1.tar.bz2\n",
        "#download LJSpeech-1.1  dataset de TTS"
      ],
      "metadata": {
        "id": "YU-yuiIToAO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>TTS - Funções utilizadas</h1>"
      ],
      "metadata": {
        "id": "TxzIe6ff0MsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import ast\n",
        "\n",
        "#--------------------------Áudio para spectrograma\n",
        "def load_mel(file_path):\n",
        "  y, sr = librosa.load(file_path, sr=22050)\n",
        "  mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=256, n_mels=80)\n",
        "  mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "  return mel_db\n",
        "\n",
        "#--------------------------Texto para token\n",
        "def tokenize_text(text):\n",
        "    return [symbol_to_id[c] for c in text if c in symbol_to_id]\n",
        "\n",
        "#--------------------------Texto para spectrograma\n",
        "def text_to_mel(text, model, max_len=200):\n",
        "    # Tokenizar e fazer padding\n",
        "    tokens = tokenize_text(text)\n",
        "    token_input = pad_sequences([tokens], maxlen=max_len, padding='post')\n",
        "\n",
        "    # Prever mel spectrogram\n",
        "    pred_mel = model.predict(token_input)\n",
        "\n",
        "    # Remover batch dimension\n",
        "    mel = pred_mel[0].T  # Transpor para shape (n_mels, time)\n",
        "    return mel\n",
        "\n",
        "#--------------------------Spectrograma para audio\n",
        "def mel_to_audio(mel_spec, sr=22050):\n",
        "    # Desfaz o dB\n",
        "    mel_spec = librosa.db_to_power(mel_spec)\n",
        "\n",
        "    # Reconstrução com Griffin-Lim\n",
        "    audio = librosa.feature.inverse.mel_to_audio(\n",
        "        mel_spec, sr=sr, n_fft=1024, hop_length=256, n_iter=60\n",
        "    )\n",
        "    return audio\n",
        "\n",
        "#---------------------------Formação do arquivo WAV\n",
        "def generate_audio_from_text(text, model, output_path='output.wav'):\n",
        "    mel = text_to_mel(text, model)\n",
        "    audio = mel_to_audio(mel)\n",
        "    sf.write(output_path, audio, samplerate=22050)\n",
        "    print(f\"Áudio salvo em: {output_path}\")\n",
        "    return audio"
      ],
      "metadata": {
        "id": "l1ghOkgM0LTL"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>TTS - PREPARAÇÃO DOS DADOS </h2>\n",
        "\n"
      ],
      "metadata": {
        "id": "_wjiOYxV6naG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import ast\n",
        "\n",
        "#==============Dataset LJSpeech em dataframe Pandas=================\n",
        "\n",
        "df = pd.read_csv('LJSpeech-1.1/metadata.csv',\n",
        "                       sep=\"|\",\n",
        "                       header=None,\n",
        "                       names=['file_id', 'text', 'normalized_text'])\n",
        "\n",
        "audios_path = []\n",
        "\n",
        "for x in df['file_id']:\n",
        "  audios_path.append(f'LJSpeech-1.1/wavs/{x}.wav')\n",
        "\n",
        "df['audio_path'] = audios_path\n",
        "\n",
        "\n",
        "#===============Função para texto em spectrogram==================\n",
        "symbols = [\n",
        "    '_',  # padding\n",
        "    ' ',  # espaço\n",
        "    '!', \"'\",'\"', '(', ')', ',', '-', '.', ':', ';', '?',\n",
        "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
        "    'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "    'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
        "]\n",
        "#Variáveis necessárias:\n",
        "symbol_to_id = {s: i for i, s in enumerate(symbols)}\n",
        "id_to_symbol = {i: s for i, s in enumerate(symbols)}\n",
        "vocab_size = len(symbols)\n",
        "\n",
        "#===================Normalizar dados do dataframe(texto>spectro / áudio>spectro)==============\n",
        "\n",
        "df['mel_spec'] = df['audio_path'].apply(load_mel)\n",
        "df['tokenized_text'] = df['normalized_text'].apply(lambda x:tokenize_text(str(x)))\n",
        "\n",
        "#Padding dos dados em variáveis de lista\n",
        "x_text = pad_sequences(df['tokenized_text'].tolist(), padding='post')\n",
        "\n",
        "max_len = max([mel.shape[1] for mel in df['mel_spec']])\n",
        "y_mel = np.array([\n",
        "    np.pad(mel, ((0, 0), (0, max_len - mel.shape[1])), mode='constant', constant_values=-80.0).T\n",
        "    for mel in df['mel_spec']\n",
        "])\n",
        "\n",
        "#=================Salvar os dados em disco (poupar RAM para o treinamento)======================\n",
        "np.save('x_text.npy', x_text)\n",
        "np.save('y_mel.npy', y_mel)\n",
        "df.to_pickle('df.pkl')"
      ],
      "metadata": {
        "id": "glE0cIuooA_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TSS - CONSTRUÇÃO MODELO E TREINAMENTO"
      ],
      "metadata": {
        "id": "7rgmwvNmFF75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import ast\n",
        "#====================Recuperar os dados de treinamento=====================\n",
        "x_text = np.load('x_text.npy')\n",
        "y_mel = np.load('y_mel.npy')\n",
        "df = pd.read_pickle('df.pkl')\n",
        "\n",
        "symbols = [\n",
        "    '_',  # padding\n",
        "    ' ',  # espaço\n",
        "    '!', \"'\",'\"', '(', ')', ',', '-', '.', ':', ';', '?',\n",
        "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
        "    'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "    'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
        "]\n",
        "\n",
        "vocab_size = len(symbols)\n",
        "\n",
        "#====================Construção do modelo==================================\n",
        "embedding_dim = 256\n",
        "encoder_units = 512\n",
        "decoder_units = 1024\n",
        "mel_dim = df['mel_spec'][0].shape[0]\n",
        "\n",
        "def build_tts_encoder_decoder():\n",
        "    #Entrada, embedding\n",
        "    text_input = layers.Input(shape=(None,), dtype='int32', name='text_input')\n",
        "    embed = layers.Embedding(input_dim = vocab_size, output_dim=embedding_dim)(text_input)\n",
        "\n",
        "    #Encoder bidirecional com memória reforçada(LSTM)\n",
        "    encoder_outputs = layers.Bidirectional(layers.LSTM(encoder_units, return_sequences=True))(embed)\n",
        "\n",
        "    #Attention(reforço do encoder em si mesmo)\n",
        "    attention = layers.Attention()([encoder_outputs, encoder_outputs])\n",
        "\n",
        "    #Decoder para gerar spectrogramas memória reforçada (LSTM)\n",
        "    decoder_lstm = layers.LSTM(decoder_units, return_sequences=True)(attention)\n",
        "    mel_output = layers.TimeDistributed(layers.Dense(mel_dim))(decoder_lstm)\n",
        "\n",
        "    #Montagem do modelo final para retornar\n",
        "    model = models.Model(inputs=text_input, outputs=mel_output)\n",
        "    return model\n",
        "\n",
        "#===========================Aplicação e treinamento do modelo=================================\n",
        "model = build_tts_encoder_decoder()\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(x_text, y_mel, batch_size=32, epochs=10, validation_split=0.1)\n",
        "\n",
        "#===========================Salvando o modelo=============================\n",
        "model.save('tts_model.h5')"
      ],
      "metadata": {
        "id": "TqQYvUXLFFOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TTS - TESTE DE UTILIZAÇÃO DO MODELO </h1>"
      ],
      "metadata": {
        "id": "ed5f0567FqkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "text = input(\"Digite o texto: \")\n",
        "generate_audio_from_text(text, model, output_path='audio_gerado.wav')\n",
        "Audio(\"audio_gerado.wav\")"
      ],
      "metadata": {
        "id": "1cZf8zUQ1XuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Opcionais </h3>"
      ],
      "metadata": {
        "id": "GfthgpeqFOCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=============Dataframe para excel (opcional para inspeção)===============\n",
        "#df.to_excel('LJSpeech.xlsx', index=False)\n",
        "\n",
        "#==============Trecho opcional para executar áudio e exibir spectrogram============\n",
        "\n",
        "mel_db = load_mel(audio_path)\n",
        "\n",
        "# AudioDisplay and Plot the Mel spectrogram\n",
        "n = 10\n",
        "file_name = df.iloc[n]['file_id']\n",
        "print(df.iloc[n]['text'])\n",
        "\n",
        "audio_path = f'LJSpeech-1.1/wavs/{file_name}.wav'\n",
        "\n",
        "display(Audio(filename=audio_path))\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "librosa.display.specshow(mel_db.T, sr=22050, hop_length=256, x_axis='time', y_axis='mel')\n",
        "\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel Spectrogram (dB)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "i6Sc8WT9FNAx",
        "outputId": "75cafd82-8717-409d-d440-c3f9ed5a184f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'audio_path' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-23-3814014373.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#==============Trecho opcional para executar áudio e exibir spectrogram============\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmel_db\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# AudioDisplay and Plot the Mel spectrogram\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'audio_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>NOVA ABORDAGEM</h1>"
      ],
      "metadata": {
        "id": "LKRTEEb7ytEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>CONVERTER ARQUIVOS DE ÁUDIO PARA PADRÕES RATE/CHANNEL/WIDTH</h2>"
      ],
      "metadata": {
        "id": "TSD88gWh1GX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "nNsFO69sysw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_dir = \"LJSpeech-1.1/wavs\"\n",
        "output_dir = \"LJSpeech-1.1/wavs16k\"\n",
        "\n",
        "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "\n",
        "for filename in tqdm(os.listdir(input_dir)):\n",
        "  if filename.endswith(\".wav\"):\n",
        "    filepath = os.path.join(input_dir, filename)\n",
        "    audio = AudioSegment.from_wav(filepath)\n",
        "\n",
        "    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)\n",
        "\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    audio.export(output_path, format=\"wav\")"
      ],
      "metadata": {
        "id": "tcsaUGLZy0I3",
        "outputId": "b9f18efc-3ca7-4ff6-c1ab-53c8e9b003b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13100/13100 [01:13<00:00, 177.34it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Testando o formato dos áudios convertidos</h2>"
      ],
      "metadata": {
        "id": "Q3ou2rYe2tu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "\n",
        "with wave.open(\"LJSpeech-1.1/wavs16k/LJ001-0001.wav\", \"rb\") as wav_file:\n",
        "    print(\"Frequência:\", wav_file.getframerate())\n",
        "    print(\"Canais:\", wav_file.getnchannels())\n",
        "    print(\"Sample width:\", wav_file.getsampwidth())  # Deve ser 2 (16-bit)"
      ],
      "metadata": {
        "id": "jwdTISJy1xxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Dataframe dos metadatas e coluna com caminho dos arquivos</h2>"
      ],
      "metadata": {
        "id": "kjZddvjq23vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "metadata = pd.read_csv('LJSpeech-1.1/metadata.csv',sep=\"|\", header=None)\n",
        "metadata.columns = ['file_id', 'text', 'normalized_text']\n",
        "metadata['wav_path'] = metadata['file_id'].apply(lambda x:f'LJSpeech-1.1/wav16k/{x}.wav')"
      ],
      "metadata": {
        "id": "DxMIWk9s2rZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extrair Mel com Librosa</h2>"
      ],
      "metadata": {
        "id": "3TEfR-BP4AJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "def wav_to_mel(wav_path, sr=16000, n_mels=80, hot_lenght=256, win_lenght=1024):\n",
        "  y, _=\n"
      ],
      "metadata": {
        "id": "6SkFHRn84V1-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}