{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP3InWMfs4WnKhWkrik/p5b",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoReis136/tensorflow/blob/main/TensorFlowTTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TTS -  DOWNLOAD DO DATASET LJSPEECH </h1>"
      ],
      "metadata": {
        "id": "8mbBho6YF0lL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar xvjf LJSpeech-1.1.tar.bz2\n",
        "#download LJSpeech-1.1  dataset de TTS"
      ],
      "metadata": {
        "id": "YU-yuiIToAO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>TTS - Funções utilizadas</h1>"
      ],
      "metadata": {
        "id": "TxzIe6ff0MsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import ast\n",
        "\n",
        "#--------------------------Áudio para spectrograma\n",
        "def load_mel(file_path):\n",
        "  y, sr = librosa.load(file_path, sr=22050)\n",
        "  mel = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=1024, hop_length=256, n_mels=80)\n",
        "  mel_db = librosa.power_to_db(mel, ref=np.max)\n",
        "  return mel_db\n",
        "\n",
        "#--------------------------Texto para token\n",
        "def tokenize_text(text):\n",
        "    return [symbol_to_id[c] for c in text if c in symbol_to_id]\n",
        "\n",
        "#--------------------------Texto para spectrograma\n",
        "def text_to_mel(text, model, max_len=200):\n",
        "    # Tokenizar e fazer padding\n",
        "    tokens = tokenize_text(text)\n",
        "    token_input = pad_sequences([tokens], maxlen=max_len, padding='post')\n",
        "\n",
        "    # Prever mel spectrogram\n",
        "    pred_mel = model.predict(token_input)\n",
        "\n",
        "    # Remover batch dimension\n",
        "    mel = pred_mel[0].T  # Transpor para shape (n_mels, time)\n",
        "    return mel\n",
        "\n",
        "#--------------------------Spectrograma para audio\n",
        "def mel_to_audio(mel_spec, sr=22050):\n",
        "    # Desfaz o dB\n",
        "    mel_spec = librosa.db_to_power(mel_spec)\n",
        "\n",
        "    # Reconstrução com Griffin-Lim\n",
        "    audio = librosa.feature.inverse.mel_to_audio(\n",
        "        mel_spec, sr=sr, n_fft=1024, hop_length=256, n_iter=60\n",
        "    )\n",
        "    return audio\n",
        "\n",
        "#---------------------------Formação do arquivo WAV\n",
        "def generate_audio_from_text(text, model, output_path='output.wav'):\n",
        "    mel = text_to_mel(text, model)\n",
        "    audio = mel_to_audio(mel)\n",
        "    sf.write(output_path, audio, samplerate=22050)\n",
        "    print(f\"Áudio salvo em: {output_path}\")\n",
        "    return audio"
      ],
      "metadata": {
        "id": "l1ghOkgM0LTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>TTS - PREPARAÇÃO DOS DADOS </h2>\n",
        "\n"
      ],
      "metadata": {
        "id": "_wjiOYxV6naG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import ast\n",
        "\n",
        "#==============Dataset LJSpeech em dataframe Pandas=================\n",
        "\n",
        "df = pd.read_csv('LJSpeech-1.1/metadata.csv',\n",
        "                       sep=\"|\",\n",
        "                       header=None,\n",
        "                       names=['file_id', 'text', 'normalized_text'])\n",
        "\n",
        "audios_path = []\n",
        "\n",
        "for x in df['file_id']:\n",
        "  audios_path.append(f'LJSpeech-1.1/wavs/{x}.wav')\n",
        "\n",
        "df['audio_path'] = audios_path\n",
        "\n",
        "\n",
        "#===============Função para texto em spectrogram==================\n",
        "symbols = [\n",
        "    '_',  # padding\n",
        "    ' ',  # espaço\n",
        "    '!', \"'\",'\"', '(', ')', ',', '-', '.', ':', ';', '?',\n",
        "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
        "    'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "    'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
        "]\n",
        "#Variáveis necessárias:\n",
        "symbol_to_id = {s: i for i, s in enumerate(symbols)}\n",
        "id_to_symbol = {i: s for i, s in enumerate(symbols)}\n",
        "vocab_size = len(symbols)\n",
        "\n",
        "#===================Normalizar dados do dataframe(texto>spectro / áudio>spectro)==============\n",
        "\n",
        "df['mel_spec'] = df['audio_path'].apply(load_mel)\n",
        "df['tokenized_text'] = df['normalized_text'].apply(lambda x:tokenize_text(str(x)))\n",
        "\n",
        "#Padding dos dados em variáveis de lista\n",
        "x_text = pad_sequences(df['tokenized_text'].tolist(), padding='post')\n",
        "\n",
        "max_len = max([mel.shape[1] for mel in df['mel_spec']])\n",
        "y_mel = np.array([\n",
        "    np.pad(mel, ((0, 0), (0, max_len - mel.shape[1])), mode='constant', constant_values=-80.0).T\n",
        "    for mel in df['mel_spec']\n",
        "])\n",
        "\n",
        "#=================Salvar os dados em disco (poupar RAM para o treinamento)======================\n",
        "np.save('x_text.npy', x_text)\n",
        "np.save('y_mel.npy', y_mel)\n",
        "df.to_pickle('df.pkl')"
      ],
      "metadata": {
        "id": "glE0cIuooA_x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TSS - CONSTRUÇÃO MODELO E TREINAMENTO"
      ],
      "metadata": {
        "id": "7rgmwvNmFF75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from IPython.display import Audio\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import ast\n",
        "#====================Recuperar os dados de treinamento=====================\n",
        "x_text = np.load('x_text.npy')\n",
        "y_mel = np.load('y_mel.npy')\n",
        "df = pd.read_pickle('df.pkl')\n",
        "\n",
        "symbols = [\n",
        "    '_',  # padding\n",
        "    ' ',  # espaço\n",
        "    '!', \"'\",'\"', '(', ')', ',', '-', '.', ':', ';', '?',\n",
        "    'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
        "    'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
        "    'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
        "    'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'\n",
        "]\n",
        "\n",
        "vocab_size = len(symbols)\n",
        "\n",
        "#====================Construção do modelo==================================\n",
        "embedding_dim = 256\n",
        "encoder_units = 512\n",
        "decoder_units = 1024\n",
        "mel_dim = df['mel_spec'][0].shape[0]\n",
        "\n",
        "def build_tts_encoder_decoder():\n",
        "    #Entrada, embedding\n",
        "    text_input = layers.Input(shape=(None,), dtype='int32', name='text_input')\n",
        "    embed = layers.Embedding(input_dim = vocab_size, output_dim=embedding_dim)(text_input)\n",
        "\n",
        "    #Encoder bidirecional com memória reforçada(LSTM)\n",
        "    encoder_outputs = layers.Bidirectional(layers.LSTM(encoder_units, return_sequences=True))(embed)\n",
        "\n",
        "    #Attention(reforço do encoder em si mesmo)\n",
        "    attention = layers.Attention()([encoder_outputs, encoder_outputs])\n",
        "\n",
        "    #Decoder para gerar spectrogramas memória reforçada (LSTM)\n",
        "    decoder_lstm = layers.LSTM(decoder_units, return_sequences=True)(attention)\n",
        "    mel_output = layers.TimeDistributed(layers.Dense(mel_dim))(decoder_lstm)\n",
        "\n",
        "    #Montagem do modelo final para retornar\n",
        "    model = models.Model(inputs=text_input, outputs=mel_output)\n",
        "    return model\n",
        "\n",
        "#===========================Aplicação e treinamento do modelo=================================\n",
        "model = build_tts_encoder_decoder()\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(x_text, y_mel, batch_size=32, epochs=10, validation_split=0.1)\n",
        "\n",
        "#===========================Salvando o modelo=============================\n",
        "model.save('tts_model.h5')"
      ],
      "metadata": {
        "id": "TqQYvUXLFFOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> TTS - TESTE DE UTILIZAÇÃO DO MODELO </h1>"
      ],
      "metadata": {
        "id": "ed5f0567FqkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "text = input(\"Digite o texto: \")\n",
        "generate_audio_from_text(text, model, output_path='audio_gerado.wav')\n",
        "Audio(\"audio_gerado.wav\")"
      ],
      "metadata": {
        "id": "1cZf8zUQ1XuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> Opcionais </h3>"
      ],
      "metadata": {
        "id": "GfthgpeqFOCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#=============Dataframe para excel (opcional para inspeção)===============\n",
        "#df.to_excel('LJSpeech.xlsx', index=False)\n",
        "\n",
        "#==============Trecho opcional para executar áudio e exibir spectrogram============\n",
        "\n",
        "mel_db = load_mel(audio_path)\n",
        "\n",
        "# AudioDisplay and Plot the Mel spectrogram\n",
        "n = 10\n",
        "file_name = df.iloc[n]['file_id']\n",
        "print(df.iloc[n]['text'])\n",
        "\n",
        "audio_path = f'LJSpeech-1.1/wavs/{file_name}.wav'\n",
        "\n",
        "display(Audio(filename=audio_path))\n",
        "\n",
        "plt.figure(figsize=(10, 4))\n",
        "\n",
        "librosa.display.specshow(mel_db.T, sr=22050, hop_length=256, x_axis='time', y_axis='mel')\n",
        "\n",
        "plt.colorbar(format='%+2.0f dB')\n",
        "plt.title('Mel Spectrogram (dB)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "i6Sc8WT9FNAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>NOVA ABORDAGEM</h1>"
      ],
      "metadata": {
        "id": "LKRTEEb7ytEX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>CONVERTER ARQUIVOS DE ÁUDIO PARA PADRÕES RATE/CHANNEL/WIDTH</h2>"
      ],
      "metadata": {
        "id": "TSD88gWh1GX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "nNsFO69sysw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "input_dir = \"LJSpeech-1.1/wavs\"\n",
        "output_dir = \"LJSpeech-1.1/wavs16k\"\n",
        "\n",
        "for filename in tqdm(os.listdir(input_dir)):\n",
        "  if filename.endswith(\".wav\"):\n",
        "    filepath = os.path.join(input_dir, filename)\n",
        "    audio = AudioSegment.from_wav(filepath)\n",
        "\n",
        "    audio = audio.set_frame_rate(16000).set_channels(1).set_sample_width(2)\n",
        "\n",
        "    output_path = os.path.join(output_dir, filename)\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    audio.export(output_path, format=\"wav\")"
      ],
      "metadata": {
        "id": "tcsaUGLZy0I3",
        "outputId": "410259f4-4963-4bdc-df70-32bfd997de4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13100/13100 [00:48<00:00, 272.00it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Testando o formato dos áudios convertidos</h2>"
      ],
      "metadata": {
        "id": "Q3ou2rYe2tu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wave\n",
        "\n",
        "with wave.open(\"LJSpeech-1.1/wavs16k/LJ001-0001.wav\", \"rb\") as wav_file:\n",
        "    print(\"Frequência:\", wav_file.getframerate())\n",
        "    print(\"Canais:\", wav_file.getnchannels())\n",
        "    print(\"Sample width:\", wav_file.getsampwidth())  # Deve ser 2 (16-bit)"
      ],
      "metadata": {
        "id": "jwdTISJy1xxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Z_MI6eY5sBh8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Dataframe dos metadatas e coluna com caminho dos arquivos</h2>"
      ],
      "metadata": {
        "id": "kjZddvjq23vj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "metadata = pd.read_csv('LJSpeech-1.1/metadata.csv',sep=\"|\", header=None)\n",
        "metadata.columns = ['file_id', 'text', 'normalized_text']\n",
        "metadata['wav_path'] = metadata['file_id'].apply(lambda x:f'LJSpeech-1.1/wav16k/{x}.wav')"
      ],
      "metadata": {
        "id": "DxMIWk9s2rZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extrair Mel com Librosa: FUNÇÃO</h2>"
      ],
      "metadata": {
        "id": "3TEfR-BP4AJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "def convert_wav_to_mel(input_dir,\n",
        "                       output_dir,\n",
        "                       sr=16000,\n",
        "                       n_fft=1024,\n",
        "                       hop_length=256,\n",
        "                       n_mels=80,\n",
        "                       power=1.0,\n",
        "                       to_db=True,\n",
        "                       verbose=True):\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    file_list = [f for f in os.listdir(input_dir) if f.endswith(\".wav\")]\n",
        "    iterator = tqdm(file_list, desc=\"Convertendo WAV → Mel\") if verbose else file_list\n",
        "\n",
        "    for filename in iterator:\n",
        "        filepath = os.path.join(input_dir, filename)\n",
        "        output_path = os.path.join(output_dir, filename.replace(\".wav\", \".npy\"))\n",
        "\n",
        "        y, _ = librosa.load(filepath, sr=sr)\n",
        "\n",
        "        mel = librosa.feature.melspectrogram(\n",
        "            y=y,\n",
        "            sr=sr,\n",
        "            n_fft=n_fft,\n",
        "            hop_length=hop_length,\n",
        "            n_mels=n_mels,\n",
        "            power=power\n",
        "        )\n",
        "\n",
        "        if to_db:\n",
        "            mel = librosa.power_to_db(mel, ref=np.max)\n",
        "\n",
        "        np.save(output_path, mel)"
      ],
      "metadata": {
        "id": "6SkFHRn84V1-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Extrair Mel com Librosa: EXECUÇÃO</h2>"
      ],
      "metadata": {
        "id": "Cahpmtk2sItT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "convert_wav_to_mel(\n",
        "    input_dir=\"LJSpeech-1.1/wavs16k\",\n",
        "    output_dir=\"LJSpeech-1.1/mels\"\n",
        ")"
      ],
      "metadata": {
        "id": "qDpNUShYsGXs",
        "outputId": "95296b3b-68e9-4de9-9081-992ae2cf34d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Convertendo WAV → Mel: 100%|██████████| 13100/13100 [02:33<00:00, 85.28it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Visualização do spectrograma (somente por diversão)</h2>"
      ],
      "metadata": {
        "id": "GcYoRifi5IKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "mel = np.load(\"LJSpeech-1.1/mels/LJ001-0001.npy\")\n",
        "plt.figure(figsize=(10, 4))\n",
        "librosa.display.specshow(mel, sr=16000, hop_length=256, x_axis=\"time\", y_axis=\"mel\")\n",
        "plt.colorbar(format=\"%+2.0f dB\")\n",
        "plt.title(\"Mel Spectrogram\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A1r2jeXnrJ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Dados tabulares para Dataframe</h2>"
      ],
      "metadata": {
        "id": "LflNfqS55c-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('LJSpeech-1.1/metadata.csv',\n",
        "                       sep=\"|\",\n",
        "                       header=None,\n",
        "                       names=['file_id', 'text', 'normalized_text'])\n",
        "\n",
        "df['normalized_text'].fillna(df['text'],inplace=True)\n",
        "df['normalized_text'].dropna(inplace=True)"
      ],
      "metadata": {
        "id": "cZHqu8vP5chG",
        "outputId": "6645e3ba-6ff9-46ed-c2bb-4a0e1c4389d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-31-2599533971.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df['normalized_text'].fillna(df['text'],inplace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h2>Tokenizar textos: Função</h2>"
      ],
      "metadata": {
        "id": "fVKgSkCS65-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(texts):\n",
        "  chars = sorted(set(''.join(texts)))\n",
        "  chars2idx = {c: i+1 for i, c in enumerate(set(chars))}\n",
        "  chars2idx['<pad>'] = 0\n",
        "  idx2chars = {i: c for c, i in chars2idx.items()}\n",
        "  return chars2idx, idx2chars"
      ],
      "metadata": {
        "id": "xYImb0oI7Aou"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = df['normalized_text'].tolist()\n",
        "\n"
      ],
      "metadata": {
        "id": "5os2Urum8NAs",
        "outputId": "7f570836-ae08-4828-8dc6-42f048e91ae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 1, 'L': 2, 'P': 3, 'd': 4, 'A': 5, 'K': 6, 't': 7, 'z': 8, '“': 9, 'V': 10, 'q': 11, 'E': 12, 'U': 13, 'c': 14, \"'\": 15, ',': 16, '(': 17, 'O': 18, 'S': 19, '[': 20, ']': 21, ')': 22, 'Q': 23, 'N': 24, 'D': 25, 'W': 26, 'b': 27, 'F': 28, 'g': 29, 'r': 30, 'f': 31, 'x': 32, 'n': 33, 'â': 34, 'ü': 35, '!': 36, 'j': 37, 'M': 38, 'h': 39, 'T': 40, 'e': 41, 'k': 42, 'l': 43, '.': 44, 'a': 45, 'H': 46, 'B': 47, ':': 48, 'R': 49, 'o': 50, 'é': 51, '|': 52, 'è': 53, 's': 54, 'i': 55, '-': 56, 'y': 57, 'u': 58, 'w': 59, '’': 60, '”': 61, 'I': 62, 'X': 63, 'à': 64, ';': 65, 'p': 66, '\"': 67, 'ê': 68, ' ': 69, 'G': 70, 'Z': 71, '?': 72, 'm': 73, 'J': 74, 'Y': 75, 'v': 76, '<pad>': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RA30pr-K9tZN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}