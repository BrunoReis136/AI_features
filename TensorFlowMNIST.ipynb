{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOodQlMYJngrGKyPqNyfEXe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoReis136/tensorflow/blob/main/TensorFlowMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MNIST COM CNN"
      ],
      "metadata": {
        "id": "yt38RpWalhui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "def model_mnist():\n",
        "  (x_train, y_train),(x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "  x_train = x_train[..., tf.newaxis].astype(\"float32\") / 255.0\n",
        "  x_test = x_test[..., tf.newaxis].astype(\"float32\") / 255.0\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.MaxPooling2D((2,2)),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dropout(0.2),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  datagen = ImageDataGenerator(\n",
        "    rotation_range = 10,\n",
        "    zoom_range = 0.1,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1\n",
        "  )\n",
        "\n",
        "  datagen.fit(x_train)\n",
        "\n",
        "  loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "  model.compile(optimizer=\"adam\",\n",
        "                loss=loss_fn,\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "  prediction_single_sample = model(x_train[:1])\n",
        "\n",
        "  probabilities_single_sample = tf.nn.softmax(prediction_single_sample).numpy()\n",
        "  print(f'Previsões previstas para a primeira amostra: {probabilities_single_sample}')\n",
        "\n",
        "  loss_single_sample = loss_fn(y_train[:1],prediction_single_sample).numpy()\n",
        "  print(f'Perda para a primeira amostra: {loss_single_sample}')\n",
        "\n",
        "  class myCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.final_acc = None\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "      logs = logs or {}\n",
        "      acc = logs.get('accuracy')\n",
        "\n",
        "      if acc is not None and acc > 0.995 :\n",
        "          print('\\nValores de Precisão ou Perda atingidos.')\n",
        "          self.final_acc = acc\n",
        "          self.model.stop_training = True\n",
        "\n",
        "  callback = myCallback()\n",
        "\n",
        "  print('Iniciando treinamento do modelo...')\n",
        "  model.fit(datagen.flow(x_train, y_train, batch_size=32), epochs=20, callbacks=[callback])\n",
        "\n",
        "  print('Avaliando modelo...')\n",
        "  model.evaluate(x_test, y_test, verbose=2)\n",
        "\n",
        "  salva_sn = input('Deseja salvar o modelo treinado?(s/n)').lower().strip()\n",
        "\n",
        "  if salva_sn == 's':\n",
        "    if callback.final_acc is not None:\n",
        "      label = round(callback.final_acc,3)*100\n",
        "    else:\n",
        "      label = 'test'\n",
        "\n",
        "    modelo_savepath = f'model_cnn({label}).keras'\n",
        "\n",
        "    try:\n",
        "      model.save(modelo_savepath)\n",
        "      print('Modelo salvo com csucesso.')\n",
        "    except Exception as e:\n",
        "      print(f'Erro ao salvar modelo: {e}')\n",
        "  else:\n",
        "    print('Modelo não salvo.')\n",
        "\n",
        "model_mnist()"
      ],
      "metadata": {
        "id": "Y-TouNUXlgIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<h1>TESTE PRÁTICO COM WIDGET INPUTS</h1>\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eQmzpcgatOg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from ipywidgets import FileUpload, Text, Button, Output, VBox, HBox\n",
        "from IPython.display import display, Image\n",
        "from io import BytesIO\n",
        "from PIL import Image as PILImage # Para manipular a imagem\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model_mnist = tf.keras.models.load_model('model_cnn(test).keras')\n",
        "\n",
        "uploader = FileUpload(\n",
        "    accept='image/*',\n",
        "    multiple=False,\n",
        "    description='Carregar Imagem'\n",
        ")\n",
        "\n",
        "label_input = Text(\n",
        "    placeholder='Digite a label correta (dígito de 0 a 9)',\n",
        "    description='Label Correta:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "test_button = Button(\n",
        "    description='Testar Modelo',\n",
        "    button_style='success',\n",
        "    tooltip='Clique para testar o modelo com a imagem e label fornecidas'\n",
        ")\n",
        "\n",
        "output_area = Output()\n",
        "\n",
        "def preprocess_image(image_bytes):\n",
        "    img = PILImage.open(BytesIO(image_bytes)).convert('L')  # escala de cinza\n",
        "    img = img.resize((28, 28))  # redimensionar\n",
        "    img_array = np.array(img) / 255.0  # normalizar\n",
        "    img_array = np.expand_dims(img_array, axis=-1)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    return img_array.astype(np.float32)\n",
        "\n",
        "class_names = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "\n",
        "def on_test_button_clicked(b):\n",
        "    with output_area:\n",
        "        output_area.clear_output()\n",
        "\n",
        "        if not uploader.value:\n",
        "            print(\"Por favor, carregue uma imagem primeiro.\")\n",
        "            return\n",
        "\n",
        "        if not label_input.value.isdigit() or int(label_input.value) not in range(10):\n",
        "          print(\"Por favor, insira uma label numérica entre 0 e 9.\")\n",
        "          return\n",
        "\n",
        "        uploaded_filename = list(uploader.value.keys())[0]\n",
        "        image_content = uploader.value[uploaded_filename]['content']\n",
        "\n",
        "        try:\n",
        "\n",
        "            processed_image = preprocess_image(image_content)\n",
        "            model_mnist(processed_image)\n",
        "            display(Image(data=image_content, width=200))\n",
        "\n",
        "            predictions = model_mnist.predict(processed_image)\n",
        "            probabilities = tf.nn.softmax(predictions[0]).numpy()\n",
        "            predicted_class_index = np.argmax(probabilities)\n",
        "            predicted_probability = np.max(probabilities)\n",
        "            predicted_class_name = class_names[predicted_class_index]\n",
        "\n",
        "            true_label = label_input.value.strip().lower()\n",
        "            predicted_label = predicted_class_name.lower()\n",
        "\n",
        "            print(f\"Previsão do Modelo: {predicted_class_name} (Probabilidade: {predicted_probability:.2f})\")\n",
        "            print(f\"Label Correta Informada: {true_label}\")\n",
        "\n",
        "            if predicted_label == true_label:\n",
        "              print(\"Resultado: ✅ O modelo reconheceu corretamente!\")\n",
        "            else:\n",
        "              print(f\"Resultado: ❌ O modelo NÃO reconheceu corretamente. Ele previu '{predicted_class_name}' mas a label correta era '{true_label}'.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Ocorreu um erro: {e}\")\n",
        "            print(\"Verifique se o pré-processamento da imagem está correto para o seu modelo (tamanho, canais, normalização).\")\n",
        "\n",
        "\n",
        "test_button.on_click(on_test_button_clicked)\n",
        "\n",
        "input_widgets = VBox([uploader, label_input, test_button])\n",
        "display(VBox([input_widgets, output_area]))"
      ],
      "metadata": {
        "id": "ma0vjJYx3-Bb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "image = Image.open(\"foto.jpg\")\n",
        "\n",
        "plt.grid = False\n",
        "plt.gray()\n",
        "plt.axis('off')\n",
        "plt.imshow(image)\n",
        "plt.show()\n",
        "\n",
        "image_transformed = np.copy(image.convert('L'))\n",
        "\n",
        "size_x = image_transformed.shape[0]\n",
        "size_y = image_transformed.shape[1]\n",
        "\n",
        "print(f'Tamanho da imagem: {size_x}px por {size_y}px')\n",
        "\n",
        "image = np.array(image.convert('L')).astype(float)\n",
        "\n",
        "filter = [[1, 0, -1],\n",
        "          [1, 0, -1],\n",
        "          [1, 0, -1]]\n",
        "\n",
        "weight = 1\n",
        "\n",
        "for x in range(1, size_x-1):\n",
        "  for y in range(1, size_y-1):\n",
        "    convolution = 0.0\n",
        "    convolution = convolution + (image[x-1, y-1] * filter[0][0])\n",
        "    convolution = convolution + (image[x-1, y] * filter[0][1])\n",
        "    convolution = convolution + (image[x-1, y+1] * filter[0][2])\n",
        "    convolution = convolution + (image[x, y-1] * filter[1][0])\n",
        "    convolution = convolution + (image[x, y] * filter[1][1])\n",
        "    convolution = convolution + (image[x, y+1] * filter[1][2])\n",
        "    convolution = convolution + (image[x+1, y-1] * filter[2][0])\n",
        "    convolution = convolution + (image[x+1, y] * filter[2][1])\n",
        "    convolution = convolution + (image[x+1, y+1] * filter[2][2])\n",
        "\n",
        "    convolution = convolution + weight\n",
        "\n",
        "    if convolution < 0:\n",
        "      convolution = 1\n",
        "    if convolution > 255:\n",
        "      convolution = 255\n",
        "\n",
        "    image_transformed[x,y] = convolution\n",
        "\n",
        "plt.gray()\n",
        "plt.grid =  False\n",
        "plt.imshow(image_transformed)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "new_x = int(size_x /2)\n",
        "new_y = int(size_y /2)\n",
        "\n",
        "newImage = np.zeros((new_x, new_y))\n",
        "\n",
        "for x in range(0, size_x , 2):\n",
        "  for y in range(0, size_y, 2):\n",
        "    pixels = []\n",
        "    pixels.append(image_transformed[x,y])\n",
        "    pixels.append(image_transformed[x+1,y])\n",
        "    pixels.append(image_transformed[x,y+1])\n",
        "    pixels.append(image_transformed[x+1,y+1])\n",
        "\n",
        "    newImage[int(x/2), int(y/2)] = max(pixels)\n",
        "\n",
        "plt.gray()\n",
        "plt.grid = False\n",
        "plt.imshow(newImage)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZHjhk44tvLTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "x_train, x_test = x_train[..., tf.newaxis].astype(\"float32\") / 255,x_test[..., tf.newaxis].astype(\"float32\") / 255\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 10,\n",
        "    zoom_range = 0.1,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1\n",
        ")\n",
        "\n",
        "datagen.fit(x_train)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape = (28, 28, 1)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(10,activation='softmax')\n",
        "])\n",
        "\n",
        "class callBack(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.final_acc = None\n",
        "  def on_epoch_end(self, epoch, logs = None):\n",
        "    logs = logs or {}\n",
        "    acc = logs.get('accuracy')\n",
        "\n",
        "    if acc is not None and acc > 0.99:\n",
        "      self.final_acc = acc\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callback = callBack()\n",
        "\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss = 'sparse_categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    datagen.flow(x_train, y_train, batch_size=32),\n",
        "    epochs = 10,\n",
        "    callbacks = [callback]\n",
        ")\n",
        "\n",
        "model.evaluate(x_test, y_test, verbose = 2)\n"
      ],
      "metadata": {
        "id": "Wfl5vGR1wpox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile('images.zip','r') as zip_ref:\n",
        "  zip_ref.extractall('images')\n",
        "\n",
        "ds_train = tf.keras.utils.image_dataset_from_directory(\n",
        "    \"images/images/training\",\n",
        "    image_size=(28,28),\n",
        "    batch_size=32,\n",
        "    label_mode = 'binary'\n",
        ")\n",
        "\n",
        "ds_valid = tf.keras.utils.image_dataset_from_directory(\n",
        "    'images/images/validation',\n",
        "    image_size = (300,300),\n",
        "    batch_size = 32,\n",
        "    label_mode = 'binary'\n",
        ")\n",
        "\n",
        "rescale_layer = tf.keras.layers.Rescaling(scale=1./255)\n",
        "\n",
        "ds_train_rescaled = ds_train.map(lambda image, label:(rescale_layer(image), label))\n",
        "ds_valid_rescaled = ds_valid.map(lambda image, label:(rescale_layer(image), label))\n",
        "\n",
        "ds_train_final = (ds_train_rescaled.cache().shuffle(buffer_size = 1000).prefetch(buffer_size = tf.data.AUTOTUNE))\n",
        "ds_valid_final = (ds_valid_rescaled.cache().prefetch(buffer_size = tf.data.AUTOTUNE))\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(28,28,3)),\n",
        "    tf.keras.layers.Conv2D(16,(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(32, (3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.Dente(512,activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2)\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
        "    metric = 'accuracy'\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    ds_train_final,\n",
        "    epochs = 15,\n",
        "    validation_data = ds_valid_final,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "])\n"
      ],
      "metadata": {
        "id": "SuHpk0FRI2OW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from io import BytesIO\n",
        "import zipfile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "#with zipfile.ZipFile('horse-or-human-train.zip','r') as file_train:\n",
        "#  file_train.extractall('horse-or-human-train')\n",
        "\n",
        "#with zipfile.ZipFile('horse-or-human-validate.zip','r') as file_validate:\n",
        "#  file_validate.extractall('horse-or-human-validate')\n",
        "\n",
        "\n",
        "\n",
        "ds_train = tf.keras.utils.image_dataset_from_directory(\n",
        "    'horse-or-human-train',\n",
        "    image_size = (300,300),\n",
        "    batch_size = 32,\n",
        "    label_mode = 'binary'\n",
        ")\n",
        "\n",
        "\n",
        "ds_validate = tf.keras.utils.image_dataset_from_directory(\n",
        "    'horse-or-human-validate',\n",
        "    image_size=(300,300),\n",
        "    batch_size = 32,\n",
        "    label_mode = 'binary'\n",
        ")\n",
        "\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "ds_train = ds_train.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "ds_validate = ds_validate.cache().prefetch(buffer_size = AUTOTUNE)\n",
        "\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Input(shape=(300,300,3)),\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (2,2), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
        "])\n",
        "\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    logs = logs or {}\n",
        "    acc = logs.get('accuracy')\n",
        "\n",
        "    if acc is not None and acc> 0.99:\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callback = myCallback()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(ds_train,\n",
        "          epochs=10,\n",
        "          verbose=1,\n",
        "          callbacks=[callback])\n",
        "\n",
        "model.evaluate(ds_validate, verbose=1)\n",
        "\n",
        "model.save('horse-or-human-model.keras')\n"
      ],
      "metadata": {
        "id": "kbtMQ4fwrDJa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widget\n",
        "from IPython.display import display, Image\n",
        "from PIL import Image as PILImage\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "model = tf.keras.models.load_model('horse-or-human-model.keras')\n",
        "\n",
        "image_up = FileUpload(accept='/image/*', multiple=False, description='Carregar Imagem')\n",
        "btn = Button(\n",
        "    description='Enviar imagem para o teste',\n",
        "    button_style='success',\n",
        "    tooltip='Clique para testar o modelo com a imagem e label fornecidas'\n",
        ")\n",
        "\n",
        "display(image)\n",
        "\n",
        "def testar_imagem():\n",
        "  with output_area:\n",
        "    output_area.clear_output()\n",
        "    classes = ['cavalo','humano']\n",
        "    previsao = model.predict(image)\n",
        "    print(previsao)\n",
        "    possibilidade = tf.nn.softmax(previsao[0]).numpy()\n",
        "    classe_provavel_index = np.argmax(possibilidade)\n",
        "    classe_provavel = classes[classe_provavel_index]\n",
        "\n",
        "    print(f'Classe provavel: {classe_provavel}')\n",
        "\n",
        "btn.on_click(testar_imagem())\n",
        "\n",
        "\n",
        "input_widgets = VBox([image_up, btn])\n",
        "output_area = Output()\n",
        "display(VBox([input_widgets, output_area]))"
      ],
      "metadata": {
        "id": "Pld5Pn2mRp6n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}